---
title: "Naver DAN 24 Review"
date: 2024-11-23 18:09:10 +0900
tags: [naver, ai, conference, review]
description: Naver DAN24 에 참여하면서 겪은 경험을 정리해뒀습니다
image: https://i.imgur.com/C6O6y1I.png
authors: haril
---

![overview](https://i.imgur.com/WR1zj8d.jpeg)

## Overview

- 참가 일시: Nov 11, 2024
- 장소: 코엑스 그랜드블룸
- 관련 링크: [DAN 24](https://dan.naver.com/24)

운좋게도 네이버에서 주관한 DAN24 에 다녀올 수 있었습니다. 결론부터 말씀드리면, **24년에 참여한 컨퍼런스 중 가장 수준이 높았다**고 할 수 있을 것 같아요. 아래는 대략적인 내용을 적어둔 것이며, 자세한 내용은 DAN24 공식페이지를 참고해주세요.

<!-- truncate -->

## 이벤트 부스

### 웨일 & 웨일 오토모티브

![wale-automotive](https://i.imgur.com/vHb3W8k.jpeg)

- [르노 그랑 콜레오스](https://www.renault.co.kr/ko/model/koleos_overview.jsp?bannerUrl=pGSEARCHKOLEOS2411&bannerSeq=1 "https://www.renault.co.kr/ko/model/koleos_overview.jsp?bannerUrl=pGSEARCHKOLEOS2411&bannerSeq=1")에 적용된 차량 OS
    - 안드로이드 기반
- 네이버의 다양한 서비스들과 연동성이 좋아보임
- 직접 시연을 본 뒤, 그랑콜레오스에 네이버 OS 가 탑재되었다는 이야기를 듣자마자 '시승해본 적은 없지만 르노 차량(그랑콜레오스)이 엄청 현대적이겠구나'라는 생각이 듬
    - 차량 인포테인먼트의 중요성
    - 그동안 전통적인 차량용 인포테인먼트가 워낙 인식이 안좋았음 (조작감, 반응성, 가시성 등등)
    - OS 가 훌륭함에도 화면비는 너무 아쉬웠고, 확실히 테슬라처럼 큰 디스플레이가 반드시 필요하다는 생각이 듬
- 그럼 그랑콜레오스의 음성 AI 는 네이버의 하이퍼클로바X 가 사용건지?
    - 르노가 SK NUGU 를 사용하는걸로 계약을 했기 때문에 아쉽게도 하이퍼클로바는 차량에 적용되지 못함
    - 하지만 만약 다른 제조업체들과 계약만 된다면 얼마든지 하이퍼클로바를 적용할 수 있음
- 안드로이드 기반 차량이면 웨일 오토모티브를 다 적용할 수 있는건지?
    - 화면비가 차량마다 달라서 최적화 작업이 필요하겠지만 적용은 가능함
    - SDV 라면 USB 를 통해 설치할 수 있을 듯
    - 모든 차량의 화면비가 통일된다면 여러모로 이점이 많을 것 같다 (규격화)

### Naver pay VR 부동산 투어

![naverpay](https://i.imgur.com/cvHSvXg.jpeg)

- 애플의 비전 프로를 사용한 VR 체험존을 운영
- 임장을 다니지 않아도 실제 주거환경과 동일한 공간을 체험할 수 있다는 점이 VR 의 장점을 잘 활용했다고 느껴짐
- 특히 VR 인만큼 가상공간에서 빠르게 여러 방을 둘러보면서 인테리어를 위한 수치를 측정하거나, 기록해둘 수 있는 점이 부동산 서비스를 제공하는데 있어서 정말 큰 장점
    - 3D 모델링만 있다면 직접 가구 배치도 가능할 것으로 보임
    - 다만 이 서비스를 이용하기 위해서는 VR 기기가 필요한데, 비전 프로 정도의 해상도를 가진 장비는 너무 비싸서 서비스의 수요가 있다해도 접근성이 아직은 제한적일 것 같다

### 네이버 지도

- 지도를 개인화할 수 있는 부분에 신경을 많이 쓰고 있는 듯한 인상을 받았다
- POI 관련 아이콘들을 모양, 색상 등 다양하게 커스텀이 가능하다
- 네이버 관련 서비스가 정말 많은 만큼 사람들이 다양한 서비스에서 생산하는 데이터(이미지가 첨부된 리뷰, 키워드, 네비게이션 목적지, 즐겨찾기 등)로 지도 개선에 활용하고 있다
    - 사람들이 많이 쓰면 쓸수록 데이터가 생산되면서 서비스가 더욱 개선될 것이라는 생각이 듬
    - 서비스의 퀼리티도 중요하지만 raw 데이터의 중요성이 느껴짐

### HyperCLOVA X

- 기술적인 관심을 가장 많이 받고 있는 중
    - 언론사들이 취재를 위해 엄청 줄을 서있었다
- Vision AI 를 강조
    - 이미지를 업로드하면 이미지에 대해 설명해줌
    - 수식이나 복잡한 그래프 등 맥락을 정확하게 이해하고 설명해주는 점이 인상적
        - 표준분포도나 그 외 복잡한 공식을 업로드했을 때 이미지에서 보이는 내용이 뭔지 이해하고 어떤 목적으로 그려진 것인지 설명하는 등
    - 웹사이트 캡처를 넣었을 때 CSS 컴포넌트를 코드로 작성해주는 기능, 그래프 이미지를 JS 로 구현할 수 있는 코드 등 코드 생성 기능도 괜찮아보임
- 네이버는 AI 기반기술부터 직접 개발하고 있음
- 국내 IT 기업 중 ChatGPT 형태의 대화형 모델 중에는 가장 앞서 있다고 생각된다
- Langchain 에서 HyperCLOVA X 를 사용할 수 있도록 기여하는 것을 확인
    - [community: Add Naver chat model & embeddings by hyper-clova · Pull Request #25162 · langchain-ai/langchain · GitHub](https://github.com/langchain-ai/langchain/pull/25162)
    - [ChatClovaX | 🦜️🔗 LangChain](https://python.langchain.com/docs/integrations/chat/naver/)

#### QnA

몇가지 질의응답을 해봤습니다.

- Q. 다른 AI 경쟁사 대비 특별히 HyperCLOVA X 를 써야하는 이유가 있다면?
    - A. 한국어에 특화되어 있기 때문에 ChatGPT, Claude 에 비해 자연스러운 설명이 가능하다.
    - Q. 요즘 발전 속도에 미루어볼 때 한국어 정도는 1년 안에 다른 경쟁사도 잘하지 않을까?
    - A. 솔직히 다른 기업들의 모델도 금방 한국어를 잘 하게 될 것이라고 생각하긴 한다. 다만 HyperCLOVA 의 경우에는 네이티브 수준의 경험을 만들어내려고 한다. 대화형으로 사용할 때 마치 현지인과 대화하는 것처럼 느껴지게 될 것이다.
- Q. 이미지를 인식하고 그걸 코드로 생성해내는 기능이 인상적. 하지만 생성된 코드의 품질은 다소 의심된다. 타모델들도 코드는 잘 만들어내지만, 막상 컴파일조차 되지 않는 코드일 때도 많다. 혹은 입력된 프롬프트는 ‘사자’ 를 표현했지만, 결과물로는 ‘사자를 닮은 무언가.. 틀리진 않은거 같은데..’ 를 생산해내는 경우도 적지 않다. HyperCLOVA 는 어떤가? 생성된 코드 품질이 어느 정도로 정확한가?
    - A. 프롬프트를 어떻게 넣냐에 따라 다르겠지만, 개인적으로 사내에서도 적극적으로 사용하고 있다. 물론 말씀하신 것처럼 항상 완벽한 코드가 생성되지는 않지만, MS 의 Copilot 수준은 되는 것 같다. 비율로 따졌을 때 80% 이상은 만족스러운 코드를 생성해내며 충분히 도움이 된다고 느끼고 있다.

한국어를 핵심 강점으로 내세우기에는 다소 애국주의적인 발상인 것 같아서 아쉽다. 문법이나 맥락 등에서 현지인 수준의 응답을 얻는 것이 그렇게 중요할까? 개발자들만 사용하는 서비스는 아니지만, 개발자 입장에서는 성능이 훨씬 중요할 것 같다.

다만 시연을 보았을 때 한국어 응답은 확실히 빨랐다. 개인적으로 사용 중인 AI 서비스 중에서는 Claude 가 한국어 응답은 가장 빠르고 품질이 좋은 것 같은데, 그에 비견될 수준. 물론 요즘 모델이 워낙 발전 속도가 빨라서 앞으로는 어떻게 될지 가늠하기 어렵다.

:::info[게다가 이미 한국어를 잘한다.]

[o1-프리뷰, 수능국어에서 97점으로 1등급 기록 \< 산업일반 \< 산업 \< 기사본문 - AI타임스](https://www.aitimes.com/news/articleView.html?idxno=165570)

:::

### 그 외. NAVERfficial, NAVER Cloud, 치지직, ZEPETO

- B2B 컨텐츠 저작권 보호 서비스 소개
- 스트리밍 플랫폼 소개 및 체험존
- 별다른 작업 없이 카메라만으로 3D 아바타를 생성할 수 있는 플랫폼 소개 및 체험존
    - (review) 파이썬으로 흔히 구현하는 얼굴 인식, 팔다리 인식 모델과 비슷하게 보이는데 다른 분야에 비해 특별하게 느껴지진 않음

![keyring](https://i.imgur.com/DpPQqdb.jpeg)

_이렇게 간단하게 키링(?)도 만들어 볼 수 있었다_

## DEVIEW 세션

- 오전은 초청된 사람만 참여할 수 있는 키노트, 오후부터 DEVIEW
- 4개의 세션에 참여했고, 각각 50분 정도씩 진행
- 기존 타기업 컨퍼런스 대비 특이한 부분은 타임테이블 상 프론트엔드 세션은 있지만 백엔드 세션이 없다는 점이였는데, 세션을 듣다보니 네이버의 백엔드 챕터는 이미 AI 와 완전히 융합되어서 AI 관련 키워드에 대해 알지 못하면 세션을 이해하기 힘든 구조였습니다.
    - = 백엔드 챕터는 자연스럽게 AI 를 모든 곳에서 활용할 수 있어야 하고, AI 챕터의 일부
    - 이 기조는 앞으로 더욱 강화될 것이라 보여집니다.

### 사용자 경험을 극대화하는 AI 기반 장소 추천 시스템 : LLM과 유저 데이터의 융합

![photo1](https://i.imgur.com/sPPoQAU.jpeg)

#### 1. 장소 추천 시스템 개요

- 장소 추천에 대한 시나리오 소개 및 용어 정의
- 기존 장소 추천 모델 소개
- AirSPACE
    - AI 기반 장소추천 시스템 개발 (2018~)
    - 취향 추천과 코스 추천에서 사용된 LLM 에 대한 소개
    - 유저가 POI 에 대해 얼마가 관심을 갖고 있는지 유추
- Contents-based Model 의 고도화가 필요
    - User 의 괌심사에 대한정의를 POI 로부터 빠르게 수집

#### 2. 추천 시스템에서 LLM의 역할

- 장소 추천에서 시도했던 LLM task
    - 추천 사유 설명 및 domain 정보 추출
    - Embedding 추출 후 similarity search
- 추천 서비스에서 LLM의 한계와 가능성
    - 개인화 부족
    - 유저 경험 무시
    - 동적 변화 반영 부족
    - 추천 다양성 부족

#### 3. 유저 장소 데이터 분석

- 장소 관련 컨텐츠 데이터 분석
- 유저들의 장소 관련 행동 데이터 분석
    - explicit 데이터 = 유저 반응 데이터 리뷰 등
    - LLM 을 통해 리뷰로부터 다양한 컨텐스트를 추출
    - 유저들이 남긴 텍스트를 모델 학습단계에 활용

#### 4. Hybrid 장소 추천 시스템 : LLM과 유저데이터의 융합

- Hybrid Model (Content-Based + Collaborative)의 필요성
- Hybrid Model에서 LLM의 역할 정의
- 유저 데이터와의 융합 방법
    - 키워드 추출 LLM 을 통해 키워드를 추출하는게 임베딩 핵심
- 위의 방법들을 이용한 서비스 소개

#### 5. 데이터 수집과 서빙 시스템

- 실제 서비스를 위한 추천 아키텍처 소개
    - 배치 + 스트리밍 방식
    - 서비스에서 발생하는 피드백은 다시 raw 데이터로 반영
    - 하둡, 아이스버그 기반 스토어 사용
        - OpenSearch 사용
            - 다양한 서비스 지원을 위해 더 좋은 성능의 벡터 검색을 살펴볼 예정
- vector 기반 추천 서빙 시 고려해야할 점

#### 6. Future Works

- content 분석 / 유저 데이터 분석 고도화 방향
- 데이터 수집 / 서빙 고도화 방향

### CLOVA-X 이미지 편집: AI 가 선사하는 픽셀 마법의 세계

#### 1. Image Editing 서비스 및 파이프라인 소개

- What?: 사진이나 그림 등의 이미지를 수정, 보정, 편집하는 기술
    - 최근 안드로이드나 iOS 에서 제공하는 AI 이미지 수정 기술이 이에 해당
- CLOVA X AI 지우개 라는 이미지 편집 모델 서비스 중
    - 퀼리티가 정말 좋다
- 편집을 원하는 물체의 윤곽선(a.k.a 누끼)를 잘 따는 것이 매우 중요

#### 2. Segmentation

- What?
    - 이미지 내에 물체 영역을 유의미하게 나누는 기술
    - 이미지 분석 및 처리를 위한 대표적인 Fundamental Computer Vision 기술
- 물체의 영역이 잘 나누어져야 이미지 편집 과정이 잘 진행된다
- Segmentation Foundation Model: SAM (Segment Anything)
    - 이미지 내의 모든 객체에 대한 Mask 추출 가능
    - 110만장의 이미지와 11억개의 masks 로 학습
- 네이버는 SAM 을 더 발전시킨 ZIM 을 개발
- 기존 Image Segmentation 은 Mask 값이 0 또는 1로만 이루어져있어서 디테일한 표현에는 한계가 있음
    - Image Matting: Mask 값이 0과 1사이로 이루어져 있음 (floating)
        - 머리카락이나 나뭇가지 등의 선명도 or 투명도 표현이 가능하기 때문에 디테일 표현에 유리
- Mask 디테일 표현력 여부가 iamge editing 의 결과에 큰 영향을 미칠 수 있음
- SAM 을 Image Matting 으로 진화시키는 것이 ZIM
- 학습에 활용할 고품질의 데이터셋을 구하는 것이 어려웠음
    - Lavel Converter Model 을 사용하여데이터셋 구축
- 기존 Pixel Decoder 의 심플한 설계로 인해 Mask 가 깨지는 Checkboard Artifacts 이슈에 취약함을 발견
    - Hierarchical Pixel Decoder 구현
        - Checkboard Artifacts 에 Robust 할 수 있는 Hierarchical Feature Pyramid Design 을 채택
        - Output Feature Map 의 해상도를 이미지의 1/2 로 개선하여 디테일한 부분까지 표현하기 유리하게
- 다양한 도메인의 23개 데이터셋에서의 정성 결과
    - Matte anything: 이미지 내의 모든 물체들에 대한 High-Quality Masks 추출 가능
- 현재는 Scribble & Brush 의 UX 를 제공하지 못함
    - 추후 지원 예정

#### 3. Generation

- overview: Diffusion Model 은 데이터를 학습하기 위해 노이즈를 단계적으로 추가하고 제거하는 방식으로 작동
    - Forward & Reverse Process
- Object Remove
    - 주어진 이미지에서 사용자가 지정한 영역의 물체를 인식하고, 이를 주변 배경과 자연스럽게 어우러지도록 생성하여 해당 영역을 대체하는 기술
    - 선택된 물체의 영역 뿐만 아니라, 선택된 영역에서 발생하는 물리적 현상(반사, 그림자 등)까지 제거하여 자연스러운 배경을 생성하는 것을 목표
- 프로젝트 초기의 모델로는 원하는 수준의 결과를 얻기 어려웠음
    - 삭제해야하는 영역에 이미지가 생성된다거나
    - 생성된 결과물의 품질이 너무 낮다거나
    - 물리적 현상까지는 삭제되지 않는다거나
- 삭제의 개념을 알려줄 수 있는 소량의 고품질 데이터셋으로 파운데이션 모델은 삭제 작업을 완벽하게 수행
- Post Processing
    - 마스킹된 부분만 제거할 경우 어색한 결과물이 생성
    - 마스킹된 부분을 Input 으로 사용하여 주변 배경을 생성 = Expanede Input Mask
    - 이렇게 확장된 부분을 원본에 입히면 물리적 현상까지 재현한 결과물 생성 가능
- 이미지 재생성 기술을 통해 마케팅 등에서 활용할 수 있을거라고 기대
- 배경 변경 모델
    - 물리적 현상이 자연스럽게 반영되도록 하는 것이 중요
        - 반사, 그림자 등
    - 학습용 데이터셋 가공에 많은 노력을 기울임 - 앞서 소개된 ZIM 모델을 활용
    - 디퓨전 모델은 토큰의 제약이 있다 = 짧은 키워드 위주로 프롬프팅하는 이유
        - 77 토큰 길이 이상의 긴 문장을 사용하도록 변경
        - 결과적으로 학습에 도움을 줌
    - 사용자는 자세한 설명을 넣기 귀찮아함
        - 자사의 HyperCLOVA X 를 사용하여 설명을 확장
    - 런칭 준비 중

### 클립 크리에이터와 네이버 유저를 연결하기: 숏폼 컨텐츠 개인화 추천

- 좀 늦게 시장에 참여했지만 빠르게 성장 중
- 홈피드에 쌓인 유저 컨텍스트만으로 유저 추천을 제공하기엔 어려웠음
- AiRSCout
    - 크게 3가지 LLM 모듈
    - 5가지 유저 컨텍스트
- 실시간으로 반영
- 클립을 처음 접하는 사용자에게는 어떻게 추천을 할까 = cold start 문제
    - 처음 서비스에 접근한 유저에게는 뭘 추천해줘야할까?
    - 일반적인 주제를 추천하면 리텐션이 떨어질 수 있다.
        - 축구만 보는 유저에게 카테고리가 같은 이유로 야구를 보여주는 경우
    - 네이버의 최근 검색 히스토리를 사용해서 추천 피드를 생성해봄
    - 실효성이 없었고, 실제 서비스 적용시 오히려 지표가 하락
        - 왜 그럴까?
- 검색은 했지만 그걸 클립으로 추천받길 원하지 않음
    - ex) 볼리비아 비자
    - 이과수 폭포
    - 아르헨티나 여행을 원하는 유저에게 아르헨티나의 스포츠나 사회이슈가 추천되는 이슈
- 검색어로부터 관심사 키워드를 추출

#### 요약 생성 질의 / 의도 세분화

- 질의만 보면 뾰족한 추천이 어려움
- 질의, 문서를 고려한 태그 생성 기술의 필요성
- HyperCLOVA X 를 활용해서 태그 생성
- 검색 로그를 활용하여 Supervised Fine-tuning
- 자주 검색되는 패턴에 bias 되는 경우가 있음 (문제)
    - gold set, teach llm 생성, student llm 생성 순으로 개선

#### 주제 분류기

- 축구만 보는 유저에게 같은 카테고리인 야구가 추천되는 문제가 있었음
- **Noise 가 제거된 고품질 데이터셋이 매우 중요**
- 서비스 적용을 위해 작은 모델이 필요. 성능은 라지 모델을 곁들인
- Guided Text Generation

## Conclusion

- 백엔드 세션은 없었고 전부 AI, Model, ML 등이 주제
    - 백엔드 라는 분류가 AI 와 결합된 느낌
- 백엔드 엔지니어라면 이제 AI 관련 키워드(LLM, RAG, fine-tunning) 정도는 자연스럽게 활용할 수 있어야 한다는 확신이 생김
    - 앞으로 AI 학습 비중을 매우 많이 늘려야겠다
- 하이퍼클로바(HCX)가 굉장히 뛰어난 퀼리티를 보여주는 점이 인상적
- LLM 의 백본까지 직접 개발하는 기술력을 가진 부분이나, 비즈니스에 딱 맞게 커스터마이징하면서 논문까지 발표하는 부분도 인상적
- 사내 핵심 아키텍처 곳곳까지 AI 를 적극적으로, 빠르게 적용하는 점이 매우 인상적
- 유저 컨텍스트로부터 키워드를 추출하는 과정이 정말 중요
- 공통적으로 **좋은 데이터(Gold set) = 좋은 결과**라는 이야기
- 왜 RAG 가 중요하고, 검색 엔진 성능이 중요한지 이해할 수 있게 됨
- ‘좋은 학습 데이터를 제공하려면 어떻게 설계해야할까’에 대한 생각을 하게 됨
- **24년에 진행된 개발 컨퍼런스 중 가장 기술적 수준이 높았다고 생각**됨

:::note

이제 올해 외부 일정은 대부분 끝났기 때문에, 다시 기술 블로그로 돌아오겠습니다 🙇.

:::

